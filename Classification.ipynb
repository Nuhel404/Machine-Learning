{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1-1**"
      ],
      "metadata": {
        "id": "arIFQczfSPGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the data from the Excel file\n",
        "file_path = '/content/drive/MyDrive/rukhsana colab/ml pro1/Titanic_train.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# View the head of the DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPOTozn4SaAs",
        "outputId": "f38d1c43-06c2-4d99-a6db-a4e2229052b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Pclass                                               Name  \\\n",
            "0            1       3                            Braund, Mr. Owen Harris   \n",
            "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
            "2            3       3                             Heikkinen, Miss. Laina   \n",
            "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
            "4            5       3                           Allen, Mr. William Henry   \n",
            "\n",
            "      Sex   Age  SibSp  Parch            Ticket     Fare Embarked  \\\n",
            "0    male  22.0      1      0         A/5 21171   7.2500        S   \n",
            "1  female  38.0      1      0          PC 17599  71.2833        C   \n",
            "2  female  26.0      0      0  STON/O2. 3101282   7.9250        S   \n",
            "3  female  35.0      1      0            113803  53.1000        S   \n",
            "4    male  35.0      0      0            373450   8.0500        S   \n",
            "\n",
            "   Target: Survived  \n",
            "0                 0  \n",
            "1                 1  \n",
            "2                 1  \n",
            "3                 1  \n",
            "4                 0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1-2**\n",
        "\n",
        "In this code, we drop the PassengerId, Name, Ticket columns using the drop() method. We then fill missing values in the Age column with the median age, and missing values in the Embarked column with the most frequent value using the fillna() method. Finally, we use the get_dummies() method to convert the Sex and Embarked columns into dummy variables, dropping the first column of each set of dummy variables to avoid multicollinearity."
      ],
      "metadata": {
        "id": "TkE3Gs5-StKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns\n",
        "df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
        "\n",
        "# Fill missing values in Age column with median age\n",
        "median_age = df['Age'].median()\n",
        "df['Age'].fillna(median_age, inplace=True)\n",
        "\n",
        "# Fill missing values in Embarked column with most frequent value\n",
        "most_frequent_embarked = df['Embarked'].mode()[0]\n",
        "df['Embarked'].fillna(most_frequent_embarked, inplace=True)\n",
        "\n",
        "# Convert categorical variables into dummy variables\n",
        "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "TdaH72MmSxAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2-1**\n",
        "\n",
        "In this code, we first separate the features (X) and target variable (y) from the DataFrame. Then we use the train_test_split() function from scikit-learn to split the data into training and testing sets. We pass in the features (X) and target variable (y), specify the test size as 0.2 (i.e., 20% of the data is used for testing), and set the random state to 42 for reproducibility. The function returns four arrays: X_train, X_test, y_train, and y_test, which we can use for training and evaluating our models."
      ],
      "metadata": {
        "id": "R-3nEgatUNK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the data into features and target variable\n",
        "X = df.drop('Fare', axis=1)\n",
        "y = df['Fare']\n",
        "\n",
        "# Splitting the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "7NOOaM1LUPxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2-2**\n",
        "\n",
        "Implementing two regression models (Linear Regression and Random Forest Regression) and evaluating their performance"
      ],
      "metadata": {
        "id": "3JrxJ_vKU4Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Implement and train the Linear Regression model\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the Linear Regression model\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Calculate the evaluation metrics for Linear Regression\n",
        "lr_mse = mean_squared_error(y_test, y_pred_lr)\n",
        "lr_mae = mean_absolute_error(y_test, y_pred_lr)\n",
        "lr_rmse = sqrt(lr_mse)\n",
        "\n",
        "# Implement and train the Random Forest Regression model\n",
        "rfr = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rfr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the Random Forest Regression model\n",
        "y_pred_rfr = rfr.predict(X_test)\n",
        "\n",
        "# Calculate the evaluation metrics for Random Forest Regression\n",
        "rfr_mse = mean_squared_error(y_test, y_pred_rfr)\n",
        "rfr_mae = mean_absolute_error(y_test, y_pred_rfr)\n",
        "rfr_rmse = sqrt(rfr_mse)\n",
        "\n",
        "# Print the evaluation metrics for both models\n",
        "print('Linear Regression - MSE: {:.2f}, MAE: {:.2f}, RMSE: {:.2f}'.format(lr_mse, lr_mae, lr_rmse))\n",
        "print('Random Forest Regression - MSE: {:.2f}, MAE: {:.2f}, RMSE: {:.2f}'.format(rfr_mse, rfr_mae, rfr_rmse))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3BAQlkPU6va",
        "outputId": "307fba20-b86b-49e4-9a7f-1f11b32ec806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression - MSE: 1445.09, MAE: 22.00, RMSE: 38.01\n",
            "Random Forest Regression - MSE: 1194.97, MAE: 15.02, RMSE: 34.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3-1**"
      ],
      "metadata": {
        "id": "SqUeCVNUVjIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_excel('/content/drive/MyDrive/rukhsana colab/ml pro1/Titanic_train.xlsx')\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
        "\n",
        "# Fill missing values in 'Age' column with the median age\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "\n",
        "# Fill missing values in 'Embarked' column with the most frequent value\n",
        "most_frequent_embarked = df['Embarked'].mode()[0]\n",
        "df['Embarked'].fillna(most_frequent_embarked, inplace=True)\n",
        "\n",
        "# Convert 'Sex' and 'Embarked' columns to numerical using dummy variables\n",
        "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "ZFcgqvn0WG6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3-2**"
      ],
      "metadata": {
        "id": "KXEmBii-WP9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# read the dataset into a DataFrame\n",
        "df = pd.read_excel('/content/drive/MyDrive/rukhsana colab/ml pro1/Titanic_train.xlsx')\n",
        "\n",
        "# clean the data\n",
        "df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
        "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('Target: Survived', axis=1), df['Target: Survived'], test_size=0.2, random_state=42)\n",
        "\n",
        "# implement logistic regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing data\n",
        "y_pred_lr = logreg.predict(X_test)\n",
        "\n",
        "# evaluate the model's performance\n",
        "print(\"Logistic Regression Model:\")\n",
        "print(\"Accuracy score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# implement decision tree classifier model\n",
        "dtc = DecisionTreeClassifier()\n",
        "dtc.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing data\n",
        "y_pred_dtc = dtc.predict(X_test)\n",
        "\n",
        "# evaluate the model's performance\n",
        "print(\"\\nDecision Tree Classifier Model:\")\n",
        "print(\"Accuracy score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68vqySHwWSFl",
        "outputId": "08547eb4-3280-4e12-8210-9f6defe314a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model:\n",
            "Accuracy score: 0.7846153846153846\n",
            "Confusion matrix:\n",
            " [[65 10]\n",
            " [18 37]]\n",
            "\n",
            "Decision Tree Classifier Model:\n",
            "Accuracy score: 0.7846153846153846\n",
            "Confusion matrix:\n",
            " [[65 10]\n",
            " [18 37]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3-3-2**\n",
        "\n",
        "In this code, we import the necessary evaluation metrics from scikit-learn and use the best model found through hyperparameter tuning to make predictions on the testing data. We then calculate and print the evaluation metrics of accuracy, precision, recall, and F1-score. "
      ],
      "metadata": {
        "id": "LxVOLZVhlWPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# define the hyperparameter grid\n",
        "hyperparameters = {'C': [0.1, 1, 10], 'penalty': ['l2', 'none']}\n",
        "# perform a grid search over the hyperparameters\n",
        "grid_search = GridSearchCV(logreg, hyperparameters, cv=5)\n",
        "\n",
        "# fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing data using the best model\n",
        "y_pred = grid_search.best_estimator_.predict(X_test)\n",
        "\n",
        "# calculate accuracy, precision, recall, and F1-score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# print the evaluation metrics\n",
        "print(\"Accuracy: {:.2f}\".format(accuracy))\n",
        "print(\"Precision: {:.2f}\".format(precision))\n",
        "print(\"Recall: {:.2f}\".format(recall))\n",
        "print(\"F1-score: {:.2f}\".format(f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng6OjbhDl453",
        "outputId": "d33d00d9-e794-48d6-9d02-d026890f957a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.78\n",
            "Precision: 0.79\n",
            "Recall: 0.67\n",
            "F1-score: 0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3-3-3 : Results Comparison**"
      ],
      "metadata": {
        "id": "uy8ZNo0OoEkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate evaluation metrics for Logistic Regression model\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "precision_lr = precision_score(y_test, y_pred_lr, average='macro')\n",
        "recall_lr = recall_score(y_test, y_pred_lr, average='macro')\n",
        "f1_lr = f1_score(y_test, y_pred_lr, average='macro')\n",
        "\n",
        "# calculate evaluation metrics for Decision Tree Classifier model\n",
        "accuracy_dtc = accuracy_score(y_test, y_pred_dtc)\n",
        "precision_dtc = precision_score(y_test, y_pred_dtc, average='macro')\n",
        "recall_dtc = recall_score(y_test, y_pred_dtc, average='macro')\n",
        "f1_dtc = f1_score(y_test, y_pred_dtc, average='macro')\n",
        "\n",
        "# print the evaluation metrics for each model\n",
        "print(\"Logistic Regression:\")\n",
        "print(\"Accuracy: {:.2f}\".format(accuracy_lr))\n",
        "print(\"Precision: {:.2f}\".format(precision_lr))\n",
        "print(\"Recall: {:.2f}\".format(recall_lr))\n",
        "print(\"F1-score: {:.2f}\".format(f1_lr))\n",
        "\n",
        "print(\"\\nDecision Tree Classifier:\")\n",
        "print(\"Accuracy: {:.2f}\".format(accuracy_dtc))\n",
        "print(\"Precision: {:.2f}\".format(precision_dtc))\n",
        "print(\"Recall: {:.2f}\".format(recall_dtc))\n",
        "print(\"F1-score: {:.2f}\".format(f1_dtc))\n",
        "\n",
        "# compare the results of different models and analyze the results\n",
        "if accuracy_lr > accuracy_dtc:\n",
        "    print(\"\\nThe Logistic Regression model performs better than the Decision Tree Classifier model.\")\n",
        "else:\n",
        "    print(\"\\nThe Decision Tree Classifier model performs better than the Logistic Regression model.\")\n",
        "\n",
        "if precision_lr > precision_dtc:\n",
        "    print(\"The Logistic Regression model has better precision than the Decision Tree Classifier model.\")\n",
        "else:\n",
        "    print(\"The Decision Tree Classifier model has better precision than the Logistic Regression model.\")\n",
        "\n",
        "if recall_lr > recall_dtc:\n",
        "    print(\"The Logistic Regression model has better recall than the Decision Tree Classifier model.\")\n",
        "else:\n",
        "    print(\"The Decision Tree Classifier model has better recall than the Logistic Regression model.\")\n",
        "\n",
        "if f1_lr > f1_dtc:\n",
        "    print(\"The Logistic Regression model has better F1-score than the Decision Tree Classifier model.\")\n",
        "else:\n",
        "    print(\"The Decision Tree Classifier model has better F1-score than the Logistic Regression model.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgT2T58jpfzu",
        "outputId": "937c1201-8a51-460a-f8bb-e3dc3584c0d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "Accuracy: 0.80\n",
            "Precision: 0.80\n",
            "Recall: 0.79\n",
            "F1-score: 0.79\n",
            "\n",
            "Decision Tree Classifier:\n",
            "Accuracy: 0.75\n",
            "Precision: 0.75\n",
            "Recall: 0.75\n",
            "F1-score: 0.75\n",
            "\n",
            "The Logistic Regression model performs better than the Decision Tree Classifier model.\n",
            "The Logistic Regression model has better precision than the Decision Tree Classifier model.\n",
            "The Logistic Regression model has better recall than the Decision Tree Classifier model.\n",
            "The Logistic Regression model has better F1-score than the Decision Tree Classifier model.\n"
          ]
        }
      ]
    }
  ]
}